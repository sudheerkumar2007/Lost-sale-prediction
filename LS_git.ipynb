{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141d4b05",
      "metadata": {
        "id": "141d4b05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score,  roc_auc_score, roc_curve,confusion_matrix,cohen_kappa_score,precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,RepeatedStratifiedKFold,GridSearchCV\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from google.cloud.bigquery import Client, QueryJobConfig\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d6d6b3",
      "metadata": {
        "id": "a1d6d6b3"
      },
      "outputs": [],
      "source": [
        "Query_Start_time = datetime.datetime.now()\n",
        "query1 = \"\"\"WITH KEEP_STORE_SKU AS (\n",
        "SELECT store_sku\n",
        "FROM (\n",
        "    SELECT *\n",
        "    FROM (\n",
        "            SELECT concat(STORE_NUM,'-',SKU) store_sku,\n",
        "                   OOO_FLAG as flag,\n",
        "                   count(1) over (partition by concat(STORE_NUM,'-',SKU),OOO_FLAG) ct,\n",
        "                   count(1) over (partition by concat(STORE_NUM,'-',SKU)) tot_ct\n",
        "            FROM `table`\n",
        "    )\n",
        "    PIVOT (ANY_VALUE(ct) Flag FOR Flag IN ('Inv', 'StockOut'))\n",
        ")\n",
        "WHERE (tot_ct!=flag_Inv OR tot_ct!=flag_StockOut) and Flag_Inv >1\n",
        "),\n",
        "\n",
        "FINAL_DATA AS (\n",
        "SELECT DISTINCT POST_DATE,\n",
        "       SKU,\n",
        "       STORE_NUM,\n",
        "       OUTLET_STRATEGY,\n",
        "       PRODUCT_KEY,\n",
        "       DAYOFWEEK_NM,\n",
        "       BRAND,\n",
        "       DEPT_STORE_GRADE,\n",
        "       DEPARTMENT_ID,\n",
        "       DEPARTMENT_DESC,\n",
        "       DIVISION_ID,\n",
        "       DIVISION_DESC,\n",
        "       BRAND_STORE_FORMAT,\n",
        "       CC,\n",
        "       CLASS_ID,\n",
        "       CLASS_DESC,\n",
        "       COLOR_ID,\n",
        "       COLOR_DESC,\n",
        "       STYLE_ID,\n",
        "       STYLE_DESC,\n",
        "       SIZE_DESC,\n",
        "       SIZE_ID,\n",
        "       STR_COUNTRY,\n",
        "       STR_STATE,\n",
        "       FISCAL_WEEK,\n",
        "       INV_OH_UT_QN,\n",
        "       SLS_UT_QN,\n",
        "       OOO_FLAG,\n",
        "       LIFE_CYCLE_FLAG,\n",
        "       ITEM_CYCLE_TYPE,\n",
        "       DEPARTMENT_INVENTORY,\n",
        "       DEPARTMENT_SALES,\n",
        "       CLASS_INVENTORY,\n",
        "       CLASS_SALES,\n",
        "       STYLE_INVENTORY,\n",
        "       STYLE_SALES,\n",
        "       STORE_CLASS_SI,\n",
        "       STORE_DEPT_SI,\n",
        "       STORE_STYLE_SI,\n",
        "       DPT_GRADE_CLASS_SI,\n",
        "       DPT_GRADE_DEPT_SI,\n",
        "       DPT_GRADE_STYLE_SI\n",
        "FROM `Sorce table`\n",
        ")\n",
        "\n",
        "SELECT * from final_data\n",
        "WHERE product_key in (SELECT STORE_SKU FROM KEEP_STORE_SKU)\n",
        "AND DEPARTMENT_ID IN (1,2,3,4,5)\"\"\"\n",
        "\n",
        "client = Client('schema')\n",
        "job1 = client.query(query1)\n",
        "df = job1.to_dataframe()\n",
        "Query_End_time = datetime.datetime.now()\n",
        "Query_Run_Time = Query_End_time-Query_Start_time\n",
        "print(Query_Run_Time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c33a6a8",
      "metadata": {
        "id": "9c33a6a8"
      },
      "outputs": [],
      "source": [
        "ls_data = df\n",
        "ls_data['Pred'] = ls_data['SLS_UT_QN'].astype(int).astype(str)\n",
        "dummy = ls_data.pop('DAYOFWEEK_NM')\n",
        "ls_data = pd.concat([ls_data,pd.get_dummies(dummy)],axis=1)\n",
        "product_list = list(ls_data['PRODUCT_KEY'].unique())\n",
        "len(product_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8a7106",
      "metadata": {
        "id": "6b8a7106"
      },
      "outputs": [],
      "source": [
        "grouped_data = ls_data.groupby('PRODUCT_KEY')\n",
        "\n",
        "# Create a list of DataFrames using dictionary comprehension\n",
        "data_groups = [group_df.copy() for _, group_df in grouped_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e5a09e",
      "metadata": {
        "id": "53e5a09e"
      },
      "outputs": [],
      "source": [
        "def model_fit(chk):\n",
        "    try:\n",
        "        #print(chk['PRODUCT_KEY'].unique())\n",
        "        #chk = ls_data[ls_data['PRODUCT_KEY']==product_list[0]]\n",
        "        chk_test = chk[chk['OOO_FLAG'] == 'StockOut']\n",
        "        chk_train = chk[chk['OOO_FLAG'] == 'Inv']\n",
        "        label_train = chk_train.pop(\"Pred\")\n",
        "        label_test = pd.DataFrame(chk_test.pop(\"Pred\"))\n",
        "        cols_selected = ['DEPARTMENT_INVENTORY','STYLE_SALES','DPT_GRADE_CLASS_SI','Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday','Wednesday']\n",
        "        #'days_to_EOL'\n",
        "        x_train, x_val, y_train, y_val = train_test_split(chk_train[cols_selected], label_train,test_size=0.1,random_state=0)#,stratify = label_train\n",
        "        # Adding Train/Test/Val Flags to data\n",
        "        chk.loc[chk_test.index, 'Train_Test_Val'] = 'Test'\n",
        "        chk.loc[x_train.index, 'Train_Test_Val'] = 'Train'\n",
        "        chk.loc[x_val.index, 'Train_Test_Val'] = 'Val'\n",
        "        rf = RandomForestClassifier()\n",
        "        mdl2 = rf.fit(x_train,y_train)\n",
        "        pred_y_val = mdl2.predict(x_val[cols_selected])\n",
        "        pred_y_val = pd.DataFrame(pred_y_val).rename(columns={0:'Predicted'})\n",
        "        pred_y_val.index = y_val.index\n",
        "        chk.loc[chk.index.isin(pred_y_val.index),['Pred']] = pred_y_val['Predicted']\n",
        "        Accuracy = accuracy_score(y_val,pred_y_val)\n",
        "        Kappa= cohen_kappa_score(y_val,pred_y_val)\n",
        "        F1_Macro = f1_score(y_val,pred_y_val,average='macro')\n",
        "        y_pred = rf.predict(chk_test[cols_selected])\n",
        "        y_pred = pd.DataFrame(y_pred).rename(columns={0:'Predicted'})\n",
        "        y_pred.index = label_test.index\n",
        "        chk.loc[chk.index.isin(y_pred.index),['Pred']] = y_pred['Predicted'] #getting the Full dataset with predicted values\n",
        "        chk['DAYOFWEEK_NM'] = (chk.loc[:, ['Friday','Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']] == 1).idxmax(1)\n",
        "        chk = chk.drop(columns=[col for col in chk if col.startswith(('DAYOFWEEK_NM_','ITEM_CYCLE_TYPE_'))])\n",
        "        op_cols = ['POST_DATE', 'SKU', 'CC','STORE_NUM','PRODUCT_KEY', 'DAYOFWEEK_NM','BRAND','DEPT_STORE_GRADE','DEPARTMENT_ID', 'DEPARTMENT_DESC','DIVISION_ID','DIVISION_DESC', 'BRAND_STORE_FORMAT', 'CLASS_ID','CLASS_DESC', 'COLOR_ID', 'COLOR_DESC', 'STYLE_ID', 'STYLE_DESC','SIZE_ID', 'SIZE_DESC', 'STR_COUNTRY', 'STR_STATE', 'FISCAL_WEEK', 'OOO_FLAG', 'LIFE_CYCLE_FLAG', 'Train_Test_Val','ITEM_CYCLE_TYPE','INV_OH_UT_QN', 'SLS_UT_QN', 'Pred']\n",
        "        chk = chk[op_cols]\n",
        "        y_pred_prob = rf.predict_proba(chk_test[cols_selected])\n",
        "        y_pred_prob = pd.DataFrame(y_pred_prob)\n",
        "        y_pred_prob.columns = ['Prob_' + str(col) for col in y_pred_prob.columns]\n",
        "        y_pred_prob.index = label_test.index\n",
        "        Predictions_df = pd.concat([chk.loc[y_pred_prob.index,['POST_DATE', 'SKU', 'STORE_NUM']],y_pred,y_pred_prob],axis=1)\n",
        "        ans = chk.merge(Predictions_df, how='left', on=['POST_DATE', 'SKU', 'STORE_NUM']).drop(columns=['Predicted'])\n",
        "        ans[['Accuracy', 'Kappa','F1_Macro']] = Accuracy,Kappa,F1_Macro\n",
        "        ans['Kappa']=ans['Kappa'].fillna(1)\n",
        "        return ans\n",
        "    except:\n",
        "        print(chk['PRODUCT_KEY'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64d836b",
      "metadata": {
        "id": "c64d836b"
      },
      "outputs": [],
      "source": [
        "#data_groups_samp = data_groups[(len(data_groups)//2):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d250d3e1",
      "metadata": {
        "id": "d250d3e1"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import multiprocessing\n",
        "import psutil\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def process_data(dgs, executor):\n",
        "    model_output = pd.DataFrame()  # Initialize an empty dataframe\n",
        "    with tqdm(total=len(dgs), desc=\"Batch_Progress\") as pbar:\n",
        "        for result_df in executor.map(model_fit, dgs):\n",
        "            model_output = pd.concat([model_output, result_df], ignore_index=True)\n",
        "            pbar.update(1)\n",
        "    return model_output\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = datetime.datetime.now()\n",
        "    master_output = pd.DataFrame()  # Initialize the master output dataframe\n",
        "\n",
        "    batch_size = 1000\n",
        "    total_batches = (len(data_groups) + batch_size - 1) // batch_size  # Calculate the total number of batches\n",
        "    print(\"total_batches Count:\", total_batches)\n",
        "\n",
        "    # Create the ProcessPoolExecutor with the desired number of processes\n",
        "    with concurrent.futures.ProcessPoolExecutor(16) as executor:\n",
        "        for i in range(total_batches):\n",
        "            batch_data_groups = data_groups[i * batch_size: (i + 1) * batch_size]  # Extract a batch of data_groups\n",
        "            print(\"Batch\", i)\n",
        "\n",
        "            # Process the batch and get the results\n",
        "            batch_output = process_data(batch_data_groups, executor)\n",
        "\n",
        "            # Append the batch results to the master output dataframe\n",
        "            master_output = pd.concat([master_output, batch_output], ignore_index=True)\n",
        "\n",
        "    end_time = datetime.datetime.now()\n",
        "    run_time = end_time - start_time\n",
        "    print(\"Total run time:\", run_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d754f95d",
      "metadata": {
        "id": "d754f95d"
      },
      "outputs": [],
      "source": [
        "master_output['Max_Prob'] = master_output[[col for col in master_output if col.startswith('Prob_')]].max(axis=1)\n",
        "master_output['SLS_UT_QN']=master_output['SLS_UT_QN'].astype(int)\n",
        "master_output['Pred']=master_output['Pred'].astype(int)\n",
        "#master_output['Model'] = 'SKU_STR_DCSINV_DCSSales_DCSSI_DCSGradeSI_no_max_features'\n",
        "master_output['Model'] = 'SKU_STR_DINV_SSales_DGradeSI_no_max_features'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b934e188",
      "metadata": {
        "id": "b934e188",
        "outputId": "6310a802-5a3b-451a-d32a-2b17b3ff61dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['POST_DATE', 'SKU', 'CC', 'STORE_NUM', 'PRODUCT_KEY', 'DAYOFWEEK_NM',\n",
              "       'BRAND', 'DEPT_STORE_GRADE', 'DEPARTMENT_ID', 'DEPARTMENT_DESC',\n",
              "       'DIVISION_ID', 'DIVISION_DESC', 'BRAND_STORE_FORMAT', 'CLASS_ID',\n",
              "       'CLASS_DESC', 'COLOR_ID', 'COLOR_DESC', 'STYLE_ID', 'STYLE_DESC',\n",
              "       'SIZE_ID', 'SIZE_DESC', 'STR_COUNTRY', 'STR_STATE', 'FISCAL_WEEK',\n",
              "       'OOO_FLAG', 'LIFE_CYCLE_FLAG', 'Train_Test_Val', 'ITEM_CYCLE_TYPE',\n",
              "       'INV_OH_UT_QN', 'SLS_UT_QN', 'Pred', 'Prob_0', 'Prob_1', 'Accuracy',\n",
              "       'Kappa', 'F1_Macro', 'Prob_2', 'Prob_3', 'Prob_4', 'Prob_5', 'Prob_6',\n",
              "       'Prob_7', 'Prob_8', 'Max_Prob', 'Model'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#master_output.columns,master_output['Model'].unique()\n",
        "master_output.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9fb70f45",
      "metadata": {
        "id": "9fb70f45"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project = 'schema')\n",
        "job_config = bigquery.LoadJobConfig()\n",
        "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
        "\n",
        "#df is the dataframe to upload, {project_id}.{dataset_id}.{table_name} is the table id in which you would like upload that dataframe\n",
        "client.load_table_from_dataframe(master_output, 'schema.table', job_config=job_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyCTws1F5iqv"
      },
      "id": "OyCTws1F5iqv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "name": "common-cpu.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
    },
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}